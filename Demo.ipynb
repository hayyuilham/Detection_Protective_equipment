{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9Hpf0cj7Nh-","executionInfo":{"status":"ok","timestamp":1709526944715,"user_tz":-420,"elapsed":7499,"user":{"displayName":"Hayyu ilham","userId":"00134032895021324374"}},"outputId":"b2b77316-3b8f-4dd9-c395-29305ce3ea11"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.31.1)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n","Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n","Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n","Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n","Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n","Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n","Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n","Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n","Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n","Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.42)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n","Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/ultralytics\n","!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNvbxo-yBNL-","executionInfo":{"status":"ok","timestamp":1709522252613,"user_tz":-420,"elapsed":10873,"user":{"displayName":"Hayyu ilham","userId":"00134032895021324374"}},"outputId":"925af0d0-4dfe-4a60-9d5c-41a9506d9b50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'ultralytics' already exists and is not an empty directory.\n","Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.1.22)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"]}]},{"cell_type":"code","source":["# input sample asset\n","\n","import gdown\n","import\n","download_link = 'https://drive.google.com/uc?id=1qQkCDS7c6-PjecYuRF7yEuD_P4Vgwi3Z'\n","output_path = '/content/video-contoh-trim.mov'\n","\n","gdown.download(download_link, output_path, quiet=False)\n","print('File berhasil diunduh dan disimpan di:', output_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"205wiKnjA0L3","executionInfo":{"status":"ok","timestamp":1709532092073,"user_tz":-420,"elapsed":2199,"user":{"displayName":"Hayyu ilham","userId":"00134032895021324374"}},"outputId":"060d9c57-339d-4d5f-b5e3-2b92a189ccd7"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1qQkCDS7c6-PjecYuRF7yEuD_P4Vgwi3Z\n","From (redirected): https://drive.google.com/uc?id=1qQkCDS7c6-PjecYuRF7yEuD_P4Vgwi3Z&confirm=t&uuid=989a394e-796c-4770-ab49-7760ec3180b5\n","To: /content/video-contoh-trim.mov\n","100%|██████████| 206M/206M [00:01<00:00, 165MB/s]"]},{"output_type":"stream","name":"stdout","text":["File berhasil diunduh dan disimpan di: /content/video-contoh-trim.mov\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["%%writefile settings.py\n","from pathlib import Path\n","import sys\n","\n","file_path = Path(__file__).resolve()\n","root_path = file_path.parent\n","\n","if root_path not in sys.path:\n","    sys.path.append(str(root_path))\n","\n","ROOT = root_path.relative_to(Path.cwd())\n","\n","# Sources\n","IMAGE = 'Image'\n","VIDEO = 'Video'\n","\n","SOURCES_LIST = [IMAGE, VIDEO]\n","\n","IMAGES_DIR = ROOT / 'images'\n","\n","VIDEO_DIR = Path('/content')\n","VIDEO_1_PATH = VIDEO_DIR / 'video-contoh-trim.mov'\n","\n","VIDEOS_DICT = {\n","    'video_1': VIDEO_1_PATH,\n","\n","}\n","\n","# Model config\n","MODEL_DIR = ROOT / 'weights'\n","DETECTION_MODEL = MODEL_DIR / 'yolov8n.pt'\n","# DETECTION_MODEL = MODEL_DIR / 'my_detection_model.pt'\n","\n","SEGMENTATION_MODEL = MODEL_DIR / 'yolov8n-seg.pt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKPZR7_oBOXJ","executionInfo":{"status":"ok","timestamp":1709533421860,"user_tz":-420,"elapsed":391,"user":{"displayName":"Hayyu ilham","userId":"00134032895021324374"}},"outputId":"35a14984-476b-4cd9-a18b-ce0c0f87bba7"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting settings.py\n"]}]},{"cell_type":"code","source":["%%writefile helper.py\n","\n","from ultralytics import YOLO\n","import time\n","import streamlit as st\n","import cv2\n","import settings\n","\n","def load_model(model_path):\n","    model = YOLO(model_path)\n","    return model\n","\n","\n","def display_tracker_options():\n","    display_tracker = st.radio(\"Display Tracker\", ('Yes', 'No'))\n","    is_display_tracker = True if display_tracker == 'Yes' else False\n","    if is_display_tracker:\n","        tracker_type = st.radio(\"Tracker\", (\"bytetrack.yaml\", \"botsort.yaml\"))\n","        return is_display_tracker, tracker_type\n","    return is_display_tracker, None\n","\n","\n","def _display_detected_frames(conf, model, st_frame, image, is_display_tracking=None, tracker=None):\n","\n","\n","    # Resize the image to a standard size\n","    image = cv2.resize(image, (720, int(720*(9/16))))\n","\n","    # Display object tracking, if specified\n","    if is_display_tracking:\n","        res = model.track(image, conf=conf, persist=True, tracker=tracker)\n","    else:\n","        # Predict the objects in the image using the YOLOv8 model\n","        res = model.predict(image, conf=conf)\n","\n","    # # Plot the detected objects on the video frame\n","    res_plotted = res[0].plot()\n","    st_frame.image(res_plotted,\n","                   caption='Detected Video',\n","                   channels=\"BGR\",\n","                   use_column_width=True\n","                   )\n","\n","\n","def play_stored_video(conf, model):\n","    source_vid = st.sidebar.selectbox(\n","        \"Choose a video...\", settings.VIDEOS_DICT.keys())\n","\n","    is_display_tracker, tracker = display_tracker_options()\n","\n","    with open(settings.VIDEOS_DICT.get(source_vid), 'rb') as video_file:\n","        video_bytes = video_file.read()\n","    if video_bytes:\n","        st.video(video_bytes)\n","\n","    if st.sidebar.button('Detect Video Objects'):\n","        try:\n","            vid_cap = cv2.VideoCapture(\n","                str(settings.VIDEOS_DICT.get(source_vid)))\n","            st_frame = st.empty()\n","            while (vid_cap.isOpened()):\n","                success, image = vid_cap.read()\n","                if success:\n","                    _display_detected_frames(conf,\n","                                             model,\n","                                             st_frame,\n","                                             image,\n","                                             is_display_tracker,\n","                                             tracker\n","                                             )\n","                else:\n","                    vid_cap.release()\n","                    break\n","        except Exception as e:\n","            st.sidebar.error(\"Error loading video: \" + str(e))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znngQotkF3Bm","executionInfo":{"status":"ok","timestamp":1709534820985,"user_tz":-420,"elapsed":510,"user":{"displayName":"Hayyu ilham","userId":"00134032895021324374"}},"outputId":"b9426a06-9525-4ccf-88cd-daf3fba6553e"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting helper.py\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","\n","from pathlib import Path\n","import PIL\n","\n","# Local Modules\n","import settings\n","import helper\n","import asset\n","\n","st.set_page_config(\n","    page_title=\"Consctruction Safety Detection using YOLO\",\n","    layout=\"wide\",\n","    initial_sidebar_state=\"expanded\"\n",")\n","\n","# Main page\n","st.header(\"Consctruction Safety Detection using YOLO\", divider='rainbow')\n","\n","# Sidebar\n","st.sidebar.header(\"Configuration\")\n","confidence = float(st.sidebar.slider( \"Select Model Confidence\", 25, 100, 40)) / 100\n","model_path = Path(settings.DETECTION_MODEL)\n","\n","# Load Pre-trained Model\n","try:\n","    model = helper.load_model(model_path)\n","except Exception as ex:\n","    st.error(f\"Unable to load model. Check path: {model_path}\")\n","    st.error(ex)\n","\n","st.sidebar.header(\"Image/Video Config\")\n","source_radio = st.sidebar.radio(\n","    \"Select Source\", settings.SOURCES_LIST)\n","\n","source_img = None\n","\n","# If image is selected\n","if source_radio == settings.IMAGE:\n","    source_img = st.sidebar.file_uploader(\n","        \"Choose an image...\", type=(\"jpg\", \"jpeg\", \"png\", 'bmp', 'webp'))\n","\n","    col1, col2 = st.columns(2)\n","\n","    with col1:\n","        try:\n","            if source_img is None:\n","                st.image(st.image(\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png\", width=400), caption=\"Default Image\", use_column_width=True)\n","            else:\n","                uploaded_image = PIL.Image.open(source_img)\n","                st.image(source_img, caption=\"Uploaded Image\",\n","                         use_column_width=True)\n","        except Exception as ex:\n","            st.error(ex)\n","\n","    with col2:\n","        if source_img is None:\n","            st.subheader('Masukkan gambar atau video anda terlebih dahulu')\n","        else:\n","            if st.sidebar.button('Detect Objects'):\n","                res = model.predict(uploaded_image,\n","                                    conf=confidence\n","                                    )\n","                boxes = res[0].boxes\n","                res_plotted = res[0].plot()[:, :, ::-1]\n","                st.image(res_plotted, caption='Detected Image',\n","                         use_column_width=True)\n","                try:\n","                    with st.expander(\"Detection Results\"):\n","                        for box in boxes:\n","                            st.write(box.data)\n","                except Exception as ex:\n","                    st.write(\"No image is uploaded yet!\")\n","\n","elif source_radio == settings.VIDEO:\n","  helper.play_stored_video(confidence, model)\n","\n","else:\n","    st.error(\"Please select a valid source type!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdMMuWAW5-ei","executionInfo":{"status":"ok","timestamp":1709533799220,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hayyu ilham","userId":"00134032895021324374"}},"outputId":"ce1db667-6296-4ef0-f8b8-a13b5db48d0a"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6_VHmbl5ong","outputId":"345ad664-0811-4a62-e9f6-f9f57ef8e683","executionInfo":{"status":"ok","timestamp":1709535302978,"user_tz":-420,"elapsed":413827,"user":{"displayName":"Hayyu ilham","userId":"00134032895021324374"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[K\u001b[?25hnpx: installed 22 in 4.951s\n","your url is: https://five-islands-appear.loca.lt\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.127.30.221:8501\u001b[0m\n","\u001b[0m\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1qQkCDS7c6-PjecYuRF7yEuD_P4Vgwi3Z\n","From (redirected): https://drive.google.com/uc?id=1qQkCDS7c6-PjecYuRF7yEuD_P4Vgwi3Z&confirm=t&uuid=0a7c202d-e65d-48ca-b9f8-00b2e1eaafad\n","To: /content/video-contoh-trim.mov\n","100% 206M/206M [00:01<00:00, 141MB/s]\n","File berhasil diunduh dan disimpan di: /content/video-contoh-trim.mov\n","\n","0: 480x640 3 persons, 245.9ms\n","Speed: 8.8ms preprocess, 245.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 384x640 1 truck, 211.8ms\n","Speed: 3.6ms preprocess, 211.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 truck, 146.3ms\n","Speed: 3.7ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 truck, 145.0ms\n","Speed: 2.6ms preprocess, 145.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 159.9ms\n","Speed: 2.7ms preprocess, 159.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 162.5ms\n","Speed: 3.7ms preprocess, 162.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 154.3ms\n","Speed: 4.1ms preprocess, 154.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 144.6ms\n","Speed: 3.3ms preprocess, 144.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 149.4ms\n","Speed: 4.3ms preprocess, 149.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.0ms\n","Speed: 3.8ms preprocess, 141.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.7ms\n","Speed: 3.5ms preprocess, 142.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 170.1ms\n","Speed: 3.2ms preprocess, 170.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 211.8ms\n","Speed: 4.2ms preprocess, 211.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 161.1ms\n","Speed: 6.2ms preprocess, 161.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 148.5ms\n","Speed: 2.8ms preprocess, 148.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 157.1ms\n","Speed: 4.2ms preprocess, 157.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 257.7ms\n","Speed: 3.7ms preprocess, 257.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 231.7ms\n","Speed: 3.6ms preprocess, 231.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 220.1ms\n","Speed: 3.8ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 223.1ms\n","Speed: 3.5ms preprocess, 223.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 250.4ms\n","Speed: 3.7ms preprocess, 250.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 232.8ms\n","Speed: 3.7ms preprocess, 232.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 220.9ms\n","Speed: 3.7ms preprocess, 220.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 220.1ms\n","Speed: 10.1ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 236.8ms\n","Speed: 3.7ms preprocess, 236.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 203.1ms\n","Speed: 4.6ms preprocess, 203.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 220.5ms\n","Speed: 4.1ms preprocess, 220.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 253.5ms\n","Speed: 4.0ms preprocess, 253.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 231.1ms\n","Speed: 3.3ms preprocess, 231.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 216.9ms\n","Speed: 3.3ms preprocess, 216.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 208.2ms\n","Speed: 3.5ms preprocess, 208.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 224.8ms\n","Speed: 4.6ms preprocess, 224.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 143.6ms\n","Speed: 2.6ms preprocess, 143.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.7ms\n","Speed: 3.3ms preprocess, 142.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 139.4ms\n","Speed: 2.9ms preprocess, 139.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 149.2ms\n","Speed: 3.6ms preprocess, 149.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 158.8ms\n","Speed: 3.1ms preprocess, 158.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 154.8ms\n","Speed: 3.8ms preprocess, 154.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 140.1ms\n","Speed: 3.5ms preprocess, 140.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.8ms\n","Speed: 3.3ms preprocess, 147.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 148.0ms\n","Speed: 4.0ms preprocess, 148.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 155.3ms\n","Speed: 3.3ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.5ms\n","Speed: 5.1ms preprocess, 142.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 213.9ms\n","Speed: 3.9ms preprocess, 213.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.2ms\n","Speed: 3.5ms preprocess, 147.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 143.4ms\n","Speed: 3.0ms preprocess, 143.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 156.9ms\n","Speed: 3.7ms preprocess, 156.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 153.7ms\n","Speed: 2.7ms preprocess, 153.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 163.4ms\n","Speed: 3.8ms preprocess, 163.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 142.3ms\n","Speed: 6.4ms preprocess, 142.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 155.3ms\n","Speed: 4.0ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 150.3ms\n","Speed: 2.8ms preprocess, 150.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 153.2ms\n","Speed: 4.6ms preprocess, 153.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 154.4ms\n","Speed: 3.2ms preprocess, 154.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 156.4ms\n","Speed: 3.8ms preprocess, 156.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 148.7ms\n","Speed: 2.5ms preprocess, 148.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 160.3ms\n","Speed: 3.9ms preprocess, 160.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.5ms\n","Speed: 2.7ms preprocess, 151.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.4ms\n","Speed: 4.7ms preprocess, 151.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 159.6ms\n","Speed: 2.8ms preprocess, 159.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 152.1ms\n","Speed: 4.0ms preprocess, 152.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.5ms\n","Speed: 2.7ms preprocess, 142.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 153.2ms\n","Speed: 3.7ms preprocess, 153.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 150.2ms\n","Speed: 3.7ms preprocess, 150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 154.8ms\n","Speed: 3.8ms preprocess, 154.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 149.1ms\n","Speed: 3.6ms preprocess, 149.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.6ms\n","Speed: 4.0ms preprocess, 151.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 152.7ms\n","Speed: 5.0ms preprocess, 152.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 158.9ms\n","Speed: 3.3ms preprocess, 158.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 150.1ms\n","Speed: 3.7ms preprocess, 150.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 135.1ms\n","Speed: 3.8ms preprocess, 135.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 145.0ms\n","Speed: 3.5ms preprocess, 145.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 180.9ms\n","Speed: 3.4ms preprocess, 180.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 150.8ms\n","Speed: 6.3ms preprocess, 150.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 134.6ms\n","Speed: 4.2ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 152.0ms\n","Speed: 3.7ms preprocess, 152.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 158.0ms\n","Speed: 2.8ms preprocess, 158.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 153.4ms\n","Speed: 3.7ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 152.7ms\n","Speed: 3.1ms preprocess, 152.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.5ms\n","Speed: 3.7ms preprocess, 151.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.9ms\n","Speed: 2.9ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 140.3ms\n","Speed: 6.6ms preprocess, 140.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 157.5ms\n","Speed: 2.6ms preprocess, 157.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 153.8ms\n","Speed: 3.3ms preprocess, 153.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 148.3ms\n","Speed: 2.8ms preprocess, 148.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.1ms\n","Speed: 3.8ms preprocess, 151.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 221.8ms\n","Speed: 5.6ms preprocess, 221.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 228.2ms\n","Speed: 3.7ms preprocess, 228.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 221.6ms\n","Speed: 3.7ms preprocess, 221.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 218.0ms\n","Speed: 4.7ms preprocess, 218.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 215.4ms\n","Speed: 3.7ms preprocess, 215.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 244.1ms\n","Speed: 4.2ms preprocess, 244.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 237.6ms\n","Speed: 3.9ms preprocess, 237.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 219.9ms\n","Speed: 5.3ms preprocess, 219.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 208.5ms\n","Speed: 3.4ms preprocess, 208.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 226.0ms\n","Speed: 4.0ms preprocess, 226.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 210.8ms\n","Speed: 6.2ms preprocess, 210.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 241.3ms\n","Speed: 3.5ms preprocess, 241.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 218.9ms\n","Speed: 3.4ms preprocess, 218.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 248.1ms\n","Speed: 9.9ms preprocess, 248.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 225.2ms\n","Speed: 4.5ms preprocess, 225.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 220.2ms\n","Speed: 8.5ms preprocess, 220.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 243.3ms\n","Speed: 4.8ms preprocess, 243.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 320.6ms\n","Speed: 5.6ms preprocess, 320.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.8ms\n","Speed: 3.3ms preprocess, 141.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 144.3ms\n","Speed: 8.2ms preprocess, 144.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 152.1ms\n","Speed: 3.8ms preprocess, 152.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 160.1ms\n","Speed: 2.8ms preprocess, 160.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 149.2ms\n","Speed: 3.2ms preprocess, 149.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 137.7ms\n","Speed: 3.2ms preprocess, 137.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.8ms\n","Speed: 3.3ms preprocess, 151.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 133.2ms\n","Speed: 4.0ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 146.4ms\n","Speed: 3.7ms preprocess, 146.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 154.6ms\n","Speed: 2.9ms preprocess, 154.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 143.6ms\n","Speed: 3.4ms preprocess, 143.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 144.4ms\n","Speed: 3.0ms preprocess, 144.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 139.7ms\n","Speed: 3.7ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 135.4ms\n","Speed: 3.6ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 135.7ms\n","Speed: 9.5ms preprocess, 135.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 145.7ms\n","Speed: 3.5ms preprocess, 145.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 145.0ms\n","Speed: 3.6ms preprocess, 145.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 132.1ms\n","Speed: 3.3ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.5ms\n","Speed: 3.7ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 140.0ms\n","Speed: 3.1ms preprocess, 140.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.7ms\n","Speed: 3.6ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 146.3ms\n","Speed: 3.3ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 139.6ms\n","Speed: 3.6ms preprocess, 139.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 131.4ms\n","Speed: 3.2ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.8ms\n","Speed: 3.5ms preprocess, 136.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 134.4ms\n","Speed: 3.3ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.7ms\n","Speed: 3.5ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 146.0ms\n","Speed: 3.6ms preprocess, 146.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 190.9ms\n","Speed: 4.5ms preprocess, 190.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 137.0ms\n","Speed: 3.7ms preprocess, 137.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.1ms\n","Speed: 3.3ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 144.4ms\n","Speed: 3.9ms preprocess, 144.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 156.1ms\n","Speed: 3.8ms preprocess, 156.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.2ms\n","Speed: 3.2ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 135.7ms\n","Speed: 4.0ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 144.3ms\n","Speed: 3.6ms preprocess, 144.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 133.1ms\n","Speed: 3.9ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 140.8ms\n","Speed: 3.9ms preprocess, 140.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 149.6ms\n","Speed: 3.5ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.2ms\n","Speed: 3.7ms preprocess, 141.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 128.8ms\n","Speed: 3.3ms preprocess, 128.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 138.4ms\n","Speed: 3.8ms preprocess, 138.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 133.3ms\n","Speed: 3.4ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.8ms\n","Speed: 3.6ms preprocess, 147.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.9ms\n","Speed: 3.3ms preprocess, 151.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 143.7ms\n","Speed: 4.9ms preprocess, 143.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 134.2ms\n","Speed: 3.4ms preprocess, 134.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 140.1ms\n","Speed: 3.7ms preprocess, 140.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 145.4ms\n","Speed: 3.3ms preprocess, 145.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 137.2ms\n","Speed: 3.7ms preprocess, 137.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 151.3ms\n","Speed: 3.1ms preprocess, 151.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.1ms\n","Speed: 3.7ms preprocess, 136.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 134.1ms\n","Speed: 3.2ms preprocess, 134.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 129.9ms\n","Speed: 2.8ms preprocess, 129.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 137.9ms\n","Speed: 3.4ms preprocess, 137.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 134.6ms\n","Speed: 6.6ms preprocess, 134.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 160.8ms\n","Speed: 2.5ms preprocess, 160.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 207.7ms\n","Speed: 3.3ms preprocess, 207.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 207.3ms\n","Speed: 3.3ms preprocess, 207.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 294.9ms\n","Speed: 3.4ms preprocess, 294.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 221.7ms\n","Speed: 3.5ms preprocess, 221.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 207.2ms\n","Speed: 3.2ms preprocess, 207.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 220.0ms\n","Speed: 4.6ms preprocess, 220.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 209.6ms\n","Speed: 3.3ms preprocess, 209.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 216.6ms\n","Speed: 3.6ms preprocess, 216.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 204.5ms\n","Speed: 3.5ms preprocess, 204.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 206.4ms\n","Speed: 3.3ms preprocess, 206.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 204.0ms\n","Speed: 3.4ms preprocess, 204.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 219.1ms\n","Speed: 3.7ms preprocess, 219.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 204.7ms\n","Speed: 3.4ms preprocess, 204.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 220.1ms\n","Speed: 3.3ms preprocess, 220.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 211.9ms\n","Speed: 3.4ms preprocess, 211.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 212.5ms\n","Speed: 3.4ms preprocess, 212.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 221.1ms\n","Speed: 3.3ms preprocess, 221.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 224.9ms\n","Speed: 5.8ms preprocess, 224.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 200.2ms\n","Speed: 3.3ms preprocess, 200.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.9ms\n","Speed: 5.1ms preprocess, 142.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 149.8ms\n","Speed: 3.3ms preprocess, 149.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.0ms\n","Speed: 4.9ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 154.1ms\n","Speed: 2.5ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 149.6ms\n","Speed: 5.3ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.2ms\n","Speed: 3.1ms preprocess, 136.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.8ms\n","Speed: 3.8ms preprocess, 142.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 140.6ms\n","Speed: 3.4ms preprocess, 140.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 144.5ms\n","Speed: 4.5ms preprocess, 144.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 145.7ms\n","Speed: 2.6ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 139.4ms\n","Speed: 3.7ms preprocess, 139.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 133.9ms\n","Speed: 3.4ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 192.0ms\n","Speed: 3.6ms preprocess, 192.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 145.2ms\n","Speed: 3.6ms preprocess, 145.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 137.7ms\n","Speed: 2.7ms preprocess, 137.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.2ms\n","Speed: 3.8ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 138.6ms\n","Speed: 3.6ms preprocess, 138.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 133.7ms\n","Speed: 3.3ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 148.3ms\n","Speed: 3.4ms preprocess, 148.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 135.5ms\n","Speed: 3.4ms preprocess, 135.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.9ms\n","Speed: 3.0ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.1ms\n","Speed: 3.8ms preprocess, 136.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 133.3ms\n","Speed: 3.7ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 139.9ms\n","Speed: 3.4ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 148.9ms\n","Speed: 3.5ms preprocess, 148.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.5ms\n","Speed: 2.4ms preprocess, 147.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 143.1ms\n","Speed: 3.1ms preprocess, 143.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 135.0ms\n","Speed: 3.7ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.0ms\n","Speed: 2.8ms preprocess, 136.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 133.5ms\n","Speed: 3.6ms preprocess, 133.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.1ms\n","Speed: 3.1ms preprocess, 147.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 143.0ms\n","Speed: 2.5ms preprocess, 143.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.2ms\n","Speed: 2.8ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 150.4ms\n","Speed: 4.3ms preprocess, 150.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 146.6ms\n","Speed: 2.3ms preprocess, 146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.4ms\n","Speed: 3.8ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 158.3ms\n","Speed: 2.5ms preprocess, 158.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 139.8ms\n","Speed: 4.0ms preprocess, 139.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 154.0ms\n","Speed: 3.1ms preprocess, 154.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 136.8ms\n","Speed: 3.3ms preprocess, 136.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 134.1ms\n","Speed: 3.6ms preprocess, 134.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 134.5ms\n","Speed: 3.2ms preprocess, 134.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 153.9ms\n","Speed: 3.1ms preprocess, 153.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 196.7ms\n","Speed: 3.3ms preprocess, 196.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 142.4ms\n","Speed: 4.0ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.7ms\n","Speed: 2.9ms preprocess, 141.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 150.4ms\n","Speed: 3.8ms preprocess, 150.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 156.8ms\n","Speed: 3.6ms preprocess, 156.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 144.4ms\n","Speed: 3.4ms preprocess, 144.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.4ms\n","Speed: 4.0ms preprocess, 147.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 147.7ms\n","Speed: 3.9ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 138.9ms\n","Speed: 3.8ms preprocess, 138.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 145.8ms\n","Speed: 3.7ms preprocess, 145.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 157.3ms\n","Speed: 3.5ms preprocess, 157.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 146.6ms\n","Speed: 4.3ms preprocess, 146.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 141.3ms\n","Speed: 3.2ms preprocess, 141.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 214.0ms\n","Speed: 3.8ms preprocess, 214.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 213.8ms\n","Speed: 3.4ms preprocess, 213.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 242.5ms\n","Speed: 7.9ms preprocess, 242.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 226.0ms\n","Speed: 3.6ms preprocess, 226.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 223.0ms\n","Speed: 3.5ms preprocess, 223.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 218.8ms\n","Speed: 3.7ms preprocess, 218.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 230.0ms\n","Speed: 3.7ms preprocess, 230.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 223.7ms\n","Speed: 3.3ms preprocess, 223.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 297.3ms\n","Speed: 3.6ms preprocess, 297.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 226.0ms\n","Speed: 3.3ms preprocess, 226.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus, 1 truck, 234.0ms\n","Speed: 3.3ms preprocess, 234.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 235.6ms\n","Speed: 3.9ms preprocess, 235.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 238.9ms\n","Speed: 3.7ms preprocess, 238.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 234.0ms\n","Speed: 3.5ms preprocess, 234.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 240.8ms\n","Speed: 8.8ms preprocess, 240.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 214.7ms\n","Speed: 3.4ms preprocess, 214.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 323.5ms\n","Speed: 3.6ms preprocess, 323.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 252.8ms\n","Speed: 6.9ms preprocess, 252.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 156.0ms\n","Speed: 3.3ms preprocess, 156.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 143.9ms\n","Speed: 4.0ms preprocess, 143.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 154.8ms\n","Speed: 3.7ms preprocess, 154.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 145.0ms\n","Speed: 3.8ms preprocess, 145.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 159.0ms\n","Speed: 2.8ms preprocess, 159.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 140.2ms\n","Speed: 3.5ms preprocess, 140.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 133.9ms\n","Speed: 3.6ms preprocess, 133.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 144.7ms\n","Speed: 3.2ms preprocess, 144.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 140.6ms\n","Speed: 3.2ms preprocess, 140.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 147.2ms\n","Speed: 3.4ms preprocess, 147.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 154.9ms\n","Speed: 3.2ms preprocess, 154.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 144.5ms\n","Speed: 3.4ms preprocess, 144.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 146.7ms\n","Speed: 2.8ms preprocess, 146.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 155.1ms\n","Speed: 3.5ms preprocess, 155.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 146.1ms\n","Speed: 3.2ms preprocess, 146.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 145.1ms\n","Speed: 3.3ms preprocess, 145.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 142.8ms\n","Speed: 3.8ms preprocess, 142.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 146.2ms\n","Speed: 3.4ms preprocess, 146.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 170.4ms\n","Speed: 3.1ms preprocess, 170.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 160.8ms\n","Speed: 3.4ms preprocess, 160.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 150.6ms\n","Speed: 2.7ms preprocess, 150.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 158.9ms\n","Speed: 3.8ms preprocess, 158.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 150.1ms\n","Speed: 2.9ms preprocess, 150.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 152.1ms\n","Speed: 4.1ms preprocess, 152.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 156.6ms\n","Speed: 3.1ms preprocess, 156.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 155.3ms\n","Speed: 11.2ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 174.0ms\n","Speed: 3.0ms preprocess, 174.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 158.4ms\n","Speed: 5.9ms preprocess, 158.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 148.6ms\n","Speed: 4.0ms preprocess, 148.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 186.7ms\n","Speed: 3.6ms preprocess, 186.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 151.7ms\n","Speed: 3.7ms preprocess, 151.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 143.3ms\n","Speed: 3.5ms preprocess, 143.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 152.5ms\n","Speed: 4.0ms preprocess, 152.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 trucks, 137.2ms\n","Speed: 2.6ms preprocess, 137.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","2024-03-04 06:54:59.135 MediaFileHandler: Missing file 136b98943e256e10f8bac56cc41d3934fdde0e0c5f23f67bd747ba99.jpg\n","\u001b[34m  Stopping...\u001b[0m\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}],"source":["!streamlit run app.py & npx localtunnel --port 8501"]}]}